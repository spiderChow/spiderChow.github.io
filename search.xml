<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>Lists</title>
      <link href="/2018/03/27/Lists/"/>
      <content type="html"><![CDATA[<p>Something about the types and delcaration and Instantiation<br>And implement the List Class and its get(), size()<br><a id="more"></a></p><h1 id="Something-about-the-types-and-delcaration-and-Instantiation"><a href="#Something-about-the-types-and-delcaration-and-Instantiation" class="headerlink" title="Something about the types and delcaration and Instantiation"></a>Something about the types and delcaration and Instantiation</h1><h2 id="memory"><a href="#memory" class="headerlink" title="memory"></a>memory</h2><p>Your computer stores information in “memory”.<br>In Java, there are 8 primitive types: byte, short, int, long, float, double, boolean, and char.</p><blockquote><p>One interesting observation is that both 72 and H are stored as 01001000.<br>This raises the question: how does a piece of Java code know how to interpret 01001000?<br>The answer is through types! Java interpreter treats them differently when printed.</p></blockquote><h2 id="delcare"><a href="#delcare" class="headerlink" title="delcare"></a>delcare</h2><p>When you <code>declare</code> a variable of a certain type, Java finds a contiguous block of <code>exactly</code> enough bits to hold a thing of that type. For example, if you declare an int, you get a block of 32 bits.   </p><p>Java creates an internal table that maps each variable name to a location.   </p><p>Java does not write anything into the reserved box when a variable is declared. In other words, there are <code>no default values</code>. As a result, the Java compiler prevents you from using a variable until after the box has been filled with bits using the <code>=</code> operator. </p><h2 id="The-Golden-Rule-of-Equals-GRoE"><a href="#The-Golden-Rule-of-Equals-GRoE" class="headerlink" title="The Golden Rule of Equals (GRoE)"></a>The Golden Rule of Equals (GRoE)</h2><p>When you write y = x, you are telling the Java interpreter to <code>copy the bits</code> from x into y.  </p><h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><p>Everything else, including arrays, is not a primitive type but rather a reference type</p><h3 id="Class-Instantiations"><a href="#Class-Instantiations" class="headerlink" title="Class Instantiations"></a>Class Instantiations</h3><p>When we instantiate an Object (e.g. Dog, Walrus, Planet):</p><ol><li>Java first <code>allocates</code> a box of bits for each instance variable of the class and fills them with a <code>default value</code> (e.g. 0, null).</li><li>The constructor then usually fills every such box with some other value.<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Walrus someWalrus;</span><br><span class="line">someWalrus = <span class="keyword">new</span> Walrus(<span class="number">1000</span>, <span class="number">8.3</span>);</span><br></pre></td></tr></table></figure></li></ol><h3 id="Reference-Type-Variable-Declarations"><a href="#Reference-Type-Variable-Declarations" class="headerlink" title="Reference Type Variable Declarations"></a>Reference Type Variable Declarations</h3><p>When we <code>declare</code> a variable of any reference type (Walrus, Dog, Planet):<br>Java allocates exactly a box of <code>size 64 bits</code>, no matter what type of object.<br>These bits can be either set to:</p><ol><li>Null (all zeros).</li><li>The 64 bit “address” of a specific instance of that class (returned by <code>new</code>).</li></ol><h3 id="Reference-Types-Obey-the-Golden-Rule-of-Equals"><a href="#Reference-Types-Obey-the-Golden-Rule-of-Equals" class="headerlink" title="Reference Types Obey the Golden Rule of Equals"></a>Reference Types Obey the Golden Rule of Equals</h3><p>copy the address</p><h2 id="Parameter-Passing"><a href="#Parameter-Passing" class="headerlink" title="Parameter Passing"></a>Parameter Passing</h2><p>In Java, we always pass by value.</p><h2 id="The-golden-rule"><a href="#The-golden-rule" class="headerlink" title="The golden rule:"></a>The golden rule:</h2><p>b = a copies the bits from a into b.<br>Passing parameters copies the bits.</p><h2 id="Instantiation-of-Arrays"><a href="#Instantiation-of-Arrays" class="headerlink" title="Instantiation of Arrays"></a>Instantiation of Arrays</h2><p>Arrays are also Objects. As we’ve seen, objects are (usually) instantiated using the new keyword.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Planet p = <span class="keyword">new</span> Planet(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, “blah.png”);</span><br><span class="line"><span class="keyword">int</span>[] x = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">95</span>, <span class="number">4</span>&#125;;</span><br></pre></td></tr></table></figure></p><p>int[] a = new int[]{0, 1, 2, 95, 4};<br>Creates a 64 bit box for storing an int array address. (declaration)<br>Creates a new Object, in this case an int array. (instantiation)<br>Puts the address of this new Object into the 64 bit box named a. (assignment)</p><p>Note: Instantiated objects can be lost!</p><h1 id="Build-our-own-list-class"><a href="#Build-our-own-list-class" class="headerlink" title="Build our own list class"></a>Build our own list class</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IntList</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> first;</span><br><span class="line">    <span class="keyword">public</span> IntList rest;        </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">IntList</span><span class="params">(<span class="keyword">int</span> f, IntList r)</span> </span>&#123;</span><br><span class="line">        first = f;</span><br><span class="line">        rest = r;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>For example, if we want to make a list of the numbers 5, 10, and 15, we can either do:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">IntList L = <span class="keyword">new</span> IntList(<span class="number">5</span>, <span class="keyword">null</span>);</span><br><span class="line">L.rest = <span class="keyword">new</span> IntList(<span class="number">10</span>, <span class="keyword">null</span>);</span><br><span class="line">L.rest.rest = <span class="keyword">new</span> IntList(<span class="number">15</span>, <span class="keyword">null</span>);</span><br></pre></td></tr></table></figure></p><p>Alternately, we could build our list <code>backwards</code>, yielding slightly nicer but harder to understand code:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">IntList L = <span class="keyword">new</span> IntList(<span class="number">15</span>, <span class="keyword">null</span>);</span><br><span class="line">L = <span class="keyword">new</span> IntList(<span class="number">10</span>, L);</span><br><span class="line">L = <span class="keyword">new</span> IntList(<span class="number">5</span>, L);</span><br></pre></td></tr></table></figure><h3 id="size"><a href="#size" class="headerlink" title="size()"></a>size()</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Return the size of the list using... recursion! */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">size</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (rest == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> + <span class="keyword">this</span>.rest.size();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/** Return the size of the list using no recursion! */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">iterativeSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    IntList p = <span class="keyword">this</span>;</span><br><span class="line">    <span class="keyword">int</span> totalSize = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (p != <span class="keyword">null</span>) &#123;</span><br><span class="line">        totalSize += <span class="number">1</span>;</span><br><span class="line">        p = p.rest;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> totalSize;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The key thing to remember about <code>recursive</code> code is that you need a <code>base case</code>. In this situation, the most reasonable base case is that rest is null, which results in a size 1 list.</p><h3 id="get"><a href="#get" class="headerlink" title="get()"></a>get()</h3>]]></content>
      
      <categories>
          
          <category> CS 61B </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> List </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>entropy</title>
      <link href="/2018/03/26/entropy/"/>
      <content type="html"><![CDATA[<p>entropy and cross entropy and relative entropy, pointwise mutual information<br><a id="more"></a></p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p><a href="https://www.zhihu.com/question/41252833" target="_blank" rel="noopener">知乎上对于交叉熵信息熵相对熵的理解</a></p><p>交叉熵，其用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出的努力的大小。<br>相对熵，其用来衡量两个取值为正的函数或概率分布之间的差异<br>相对熵 = 某个策略的交叉熵 - 信息熵（根据系统真实分布计算而得的信息熵，为最优策略</p><hr><p>PMI（Pointwise Mutual Information）<br>$$PMI(x;y)=log p(x,y)/p(x)p(y)=log p(x|y)/p(x)=logp(y|x)/p(y)$$</p><p>如果x跟y不相关，则p(x,y)=p(x)p(y)。二者相关性越大，则p(x,y)就相比于p(x)p(y)越大</p><blockquote><p>例子<br>举个自然语言处理中的例子来说，我们想衡量like这个词的极性（正向情感还是负向情感）。我们可以预先挑选一些正向情感的词，比如good。然后<br>我们算like跟good的PMI，即： </p><blockquote><p>PMI(like,good)=logp(like,good)p(like)p(good)<br>其中p(like)是like在语料库中出现的概率（出现次数除以总词数N），p(like,good)<br>表示like跟good在一句话中同时出现的概率（like跟good同时出现的次数除以N2）。<br>PMI(like,good)越大表示like的正向情感倾向就越明显</p></blockquote></blockquote>]]></content>
      
      <categories>
          
          <category> Maths </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>LDA</title>
      <link href="/2018/03/26/LDA/"/>
      <content type="html"><![CDATA[<p>gggg<br><a id="more"></a></p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"> </script>]]></content>
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>Stanford Ner</title>
      <link href="/2018/03/20/Stanford-Ner/"/>
      <content type="html"><![CDATA[<p>To find how to train the model incrementally, e.g. if the client add a sentence, then a updated model should be commited. For efficience, we should only train the new sentence instead of train all the corpus again.</p><a id="more"></a><p>Likelihood:</p>]]></content>
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Machine learning </tag>
            
            <tag> CRF </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>keys extraction algorithm</title>
      <link href="/2018/03/19/keys-extraction-algorithm/"/>
      <content type="html"><![CDATA[<p>TextRank, TPR, RAKE<br><a id="more"></a></p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="TextRank"><a href="#TextRank" class="headerlink" title="TextRank"></a>TextRank</h1><p><a href="https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf" target="_blank" rel="noopener">TextRank: Bringing Order into Texts</a><br>2004 EMNLP, Rada Mihalcea and Paul Tarau</p><p>$$S(V_i) = (1-d)+d*\Sigma_{j\in IN(V_i)} S(V_j)/|Out(V_j)|$$</p><p>Graph:      </p><ul><li>Vertice: syntactic filters select only lexical units of a certain part of speech. One can for instance con- sider only nouns and verbs for addition to the graph, and consequently draw potential edges based only on relations that can be established between nouns and verbs.</li><li>Edge: We are using a co-occurrence relation, controlled by the distance between word occurrences: two vertices are connected if their corresponding lexical units co-occur within a window of maximum words, where can be set anywhere from 2 to 10 words. Co-occurrence links express relations between syntactic element.</li></ul><p>Steps:</p><ul><li>The text is tokenized, and annotated with part of speech tags – a preprocessing step required to enable the application of syntactic filters.</li><li>After the graph is constructed (undirected unweighted graph), the score associated with each vertex is set to an initial value of 1, and the ranking algorithm described is run on the graph for several iterations until it converges – usually for 20-30 iterations, at a threshold of 0.0001.</li><li>Top vertices in the ranking are retained for post-processing. Sequences of adjacent keywords are collapsed into a multi-word keyword.</li></ul><p><img src="keys-extraction-algorithm/textrank.png" alt=""></p><h1 id="Topical-PageRank"><a href="#Topical-PageRank" class="headerlink" title="Topical PageRank"></a>Topical PageRank</h1><p><a href="http://www.personal.psu.edu/wzh112/publications/emnlp2010.pdf" target="_blank" rel="noopener">Automatic keyphrase extraction via topic decomposition. Liu 2010</a><br>2010 EMNLP, Zhiyuan Liu, Wenyi Huang, Yabin Zheng and Maosong Sun</p><p>Word graph:<br>The link directions are determined as follows. When sliding a W-width window, at each position, we add links from the first word pointing to other words within the window. Since keyphrases are usually noun phrases, we only add adjectives and nouns in word graph.</p><blockquote><p>LDA:<br>N 文章长度，满足泊松分布（越长越少，越短越少）<br>一个文章的topic分布 θ ~ Dir(alpha) alpha是topic的一个分布情况。Dir: 将一个分布换成另一个分布</p><p>topic z_n ~multinomial(θ)<br>w ~ p(w|z_n,beta)<br>似然函数<br>变分推断，EM算法(含有隐蔽那辆的时候求最大似然)<br>VAE: 似然 x-&gt;y ，引入隐变量 x-&gt;h-&gt;y,利用琴生不等式，变成 含有KL距离</p></blockquote><blockquote><p>The <code>candidate keyphrases</code> of a document is obtained as follows:  </p><ul><li>The document is first tokenized.  </li><li>After that, we annotate the document with (POS) tags.   </li><li>Third, we extract noun phrases with pattern (adjective)* (noun)+.  </li></ul></blockquote><blockquote><p>the ranking score of a candidate keyphrase is computed by summing up the ranking scores of all words within the phrase.</p></blockquote><p>PageRank –&gt; Topical PageRank</p><p>$$R(V_i) = (1-\lambda)(1/|V|)+\lambda \Sigma_{j\in IN(V_i)} R(V_j)* weight(V_j,V_i)/|Out(V_j)|$$</p><p>==&gt; Biased PageRank: not equal probabilities of random jump to all vertices.</p><p>$$R_z(V_i) = (1-\lambda)p_z(V_i)+\lambda \Sigma_{j\in IN(V_i)} R_Z(V_j)* weight(V_j,V_i)/|Out(V_j)|$$</p><blockquote><p>Topic distribution of each word: pr(z|w)<br>LDA: unsurpvised<br>$p_z(V_i)$=pr(z|w) or pr(w|z) or pr(z|w)pr(w|z)</p></blockquote><p>In TPR for keyphrase extraction, we first compute the ranking scores of candidate keyphrases separately for each topic.<br>For each candidate keyphrase , we compute its final ranking score as </p><p>$$R(p)=\Sigma_zR_z(p)*pr(z|d)$$</p><p><img src="keys-extraction-algorithm/TPR.png" alt=""></p><h1 id="Rapid-automatic-keyword-extraction-RAKE"><a href="#Rapid-automatic-keyword-extraction-RAKE" class="headerlink" title="Rapid automatic keyword extraction (RAKE)"></a>Rapid automatic keyword extraction (RAKE)</h1><p><a href="https://www.researchgate.net/publication/227988510_Automatic_Keyword_Extraction_from_Individual_Documents" target="_blank" rel="noopener">Automatic keyword extraction from individual documents, Stuart Rose, Dave Engel, Nick Cramer and Wendy Cowley, 2010</a></p><p>very efficient~</p><p>The above paper even has a good example.</p><h3 id="Candidate-keywords"><a href="#Candidate-keywords" class="headerlink" title="Candidate keywords"></a>Candidate keywords</h3><blockquote><p>First, the document text is split into an array of words by the specified word delimiters.<br>This array is then split into sequences of contiguous words at phrase delimiters and stop word positions. </p></blockquote><h3 id="Word-co-occurrences-Graph"><a href="#Word-co-occurrences-Graph" class="headerlink" title="Word co-occurrences Graph"></a>Word co-occurrences Graph</h3><blockquote><p>After get the nodes of the graph, we would add the edges corresponding with the word co-occurrences.<br>The graph is represented by a <code>Matrix</code>.<br>Elements of the matrix is the word co-occurrences counts.</p></blockquote><h3 id="Score-of-candidiate-sum-of-its-member-word-scores"><a href="#Score-of-candidiate-sum-of-its-member-word-scores" class="headerlink" title="Score of candidiate (sum of its member word scores):"></a>Score of candidiate (sum of its member word scores):</h3><blockquote><p>We evaluated several metrics for calculating word scores, based on the degree and frequency of word vertices in the graph:<br>ratio of degree to frequency (deg(w)/freq(w)).<br>(I think the ratio is similar with the TFIDF)</p></blockquote><h3 id="Adjoining-keywords"><a href="#Adjoining-keywords" class="headerlink" title="Adjoining keywords"></a>Adjoining keywords</h3><p>A new candidate keyword is then created as a combination of those keywords and their interior stop words.</p><h3 id="Top-T"><a href="#Top-T" class="headerlink" title="Top T"></a>Top T</h3><p>one of third</p><h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><p>The collection consists of <code>2000 Inspec abstracts</code> for journal papers from Computer Science and Information Technology. The abstracts are divided into a training set with 1000 abstracts, a validation set with 500 abstracts, and a testing set with 500 abstracts. We followed the approach described in Mihalcea and Tarau (2004), using the testing set for evaluation because <code>RAKE does not require a training set</code>. Extracted keywords for each abstract are compared against the abstract’s associated set of manually assigned uncontrolled keywords.</p><p><img src="keys-extraction-algorithm/Rake.png" alt=""></p><h1 id="Single-document-keyphrase-extraction-using-neighborhood-knowledge"><a href="#Single-document-keyphrase-extraction-using-neighborhood-knowledge" class="headerlink" title="Single document keyphrase extraction using neighborhood knowledge"></a>Single document keyphrase extraction using neighborhood knowledge</h1><p>AAAI 2008<br><a href="http://www.aaai.org/Papers/AAAI/2008/AAAI08-136.pdf" target="_blank" rel="noopener">Single document keyphrase extraction using neighborhood knowledge, Xiaojun Wan and Jianguo Xiao 2008</a></p><p>Abstract: </p><blockquote><p>This paper proposes to use a <code>small number of nearest neighbor documents</code> to provide more knowledge to improve single document keyphrase extraction. A specified document is expanded to a small document set by adding a few neighbor documents close to the document, and the graph-based ranking algorithm is then applied on the expanded document set to make use of both the local information in the specified document and the global information in the neighbor documents </p></blockquote>]]></content>
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keywords Extraction </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Keywords Extraction</title>
      <link href="/2018/03/17/Keywords-Extraction/"/>
      <content type="html"><![CDATA[<p>Finding some reliable algorithm in keywords extraction on a document of 300-500 words.<br><a id="more"></a></p><p><a href="http://acl2014.org/acl2014/P14-1/pdf/P14-1119.pdf" target="_blank" rel="noopener">Automatic Keyphrase Extraction: A Survey of the State of the Art</a> by Kazi Saidul Hasan and Vincent Ng, 2014<br><a href="http://aclweb.org/anthology/P17-1102" target="_blank" rel="noopener">PositionRank: An Unsupervised Approach to Keyphrase Extraction from Scholarly Documents</a><br><a href="http://aclweb.org/anthology/D/D16/D16-1191.pdf" target="_blank" rel="noopener">A Graph Degeneracy-based Approach to Keyword Extraction</a></p><h1 id="Keyphrase-Extraction-Approaches"><a href="#Keyphrase-Extraction-Approaches" class="headerlink" title="Keyphrase Extraction Approaches"></a>Keyphrase Extraction Approaches</h1><p>Two steps: </p><ul><li>extracting a list of words/phrases that serve as candidate keyphrases using some heuristics  </li><li>determining which of these candidate keyphrases are correct keyphrases using <code>supervised</code>  or <code>unsupervised</code> approaches.</li></ul><h2 id="Selecting-Candidate-Words-and-Phrases"><a href="#Selecting-Candidate-Words-and-Phrases" class="headerlink" title="Selecting Candidate Words and Phrases"></a>Selecting Candidate Words and Phrases</h2><p>These rules are designed to avoid spurious instances and keep the number of candidates to a minimum.<br>Typical heuristics include:  </p><ol><li>using a <code>stop word</code> list to remove stop words <a href="">Liu et al., 2009b</a>,   </li><li>allowing words with certain <code>part-of-speech tags</code> (e.g., nouns, adjectives, verbs) to be candidate keywords <a href="">Mihalcea and Tarau, 2004; Wan and Xiao, 2008b; Liu et al., 2009a</a>,   </li><li>allowing n-grams that appear in <code>Wikipedia article titles</code> to be candidates <a href="">Grineva et al., 2009</a>,  </li><li>extracting n-grams <a href="">Witten et al., 1999; Hulth, 2003; Medelyan et al., 2009</a> or noun phrases <a href="">Barker and Cornacchia, 2000; Wu et al., 2005</a> that satisfy <code>pre-defined lexico-syntactic pattern(s)</code> <a href="">Nguyen and Phan, 2009</a>.</li></ol><p>Different pruning heuristics have been designed to <code>prune</code> candidates that are unlikely to be keyphrases (Huang et al., 2006; Kumar and Srinathan, 2008; El-Beltagy and Rafea, 2009; You et al., 2009; Newman et al., 2012).</p><hr><h2 id="Supervised-Approaches"><a href="#Supervised-Approaches" class="headerlink" title="Supervised Approaches"></a>Supervised Approaches</h2><p>keyphrase extraction is formulated as a binary classification problem, where candidate phrases are classified as either positive (i.e., keyphrases) or negative (i.e., non-keyphrases).  </p><p>Research on supervised approaches to keyphrase extraction has focused on two issues: <code>task reformulation</code> and <code>feature design</code>. </p><h3 id="Task-Reformulation"><a href="#Task-Reformulation" class="headerlink" title="Task Reformulation"></a>Task Reformulation</h3><h3 id="Feature-Design"><a href="#Feature-Design" class="headerlink" title="Feature Design"></a>Feature Design</h3><hr><h2 id="Unsupervised-Approaches"><a href="#Unsupervised-Approaches" class="headerlink" title="Unsupervised Approaches"></a>Unsupervised Approaches</h2><p>Four Group:</p><h3 id="0-The-ranking-based-on-tf-idf-has-been-shown-to-work-well-in-practice-Hasan-and-Ng-2014-2010-despite-its-simplicity"><a href="#0-The-ranking-based-on-tf-idf-has-been-shown-to-work-well-in-practice-Hasan-and-Ng-2014-2010-despite-its-simplicity" class="headerlink" title="0.The ranking based on tf-idf has been shown to work well in practice Hasan and Ng, 2014, 2010, despite its simplicity."></a>0.The ranking based on <code>tf-idf</code> has been shown to work well in practice <a href="">Hasan and Ng, 2014, 2010</a>, despite its simplicity.</h3><h3 id="1-Graph-Based-Ranking"><a href="#1-Graph-Based-Ranking" class="headerlink" title="1. Graph-Based Ranking"></a>1. Graph-Based Ranking</h3><p>Importance :a candidate is important if it is related to (1) a large number of candidates and (2) candidates that are important.  </p><ol><li>build a graph: node -&gt; candidate keyphrase; edge -&gt; relateness; weight -&gt; Syntactic or/and Semantic relatedness</li><li>rank the node via graph-based ranking methods: egde -&gt; vote;   <blockquote><p>A node’s score in the graph is defined recursively in terms of the edges it has and the scores of the neighboring nodes.</p></blockquote></li></ol><ul><li><code>TextRank</code> <a href="">Mihalcea and Tarau, 2004</a><blockquote><p>Applying PageRank on a word graph built from adjacent words within a document.<br>the nodes of graphs-of-words are ranked based on a modified version of the PageRank algorithm taking edge weights into account, and the top p% vertices are kept as keywords.<br>It does not guarantee that all the main topics will be represented by the extracted keyphrases.</p></blockquote></li><li><code>SingleRank</code><a href="">Wan and Xiao 2008</a><blockquote><p>Extended TextRank by adding weighted edges between words that co-occur in a window of variable size w ≥ 2.</p></blockquote></li><li><code>ExpandRank</code><a href="">Wan and Xiao 2008</a><blockquote><p>Textually-similar neighboring documents are included in ExpandRank (Wan and Xiao, 2008) to compute more accurate word co-occurrence information</p></blockquote></li></ul><p>Researchers have computed relatedness between candidates using <code>co-occurrence counts</code> (Mihalcea and Tarau, 2004; Matsuo and Ishizuka, 2004) and <code>semantic relatedness</code> (Grineva et al., 2009), and represented the relatedness information collected from a document as a graph (Mihalcea and Tarau, 2004; Wan and Xiao, 2008a; Wan and Xiao, 2008b; Bougouin et al., 2013).</p><h3 id="2-Topic-Based-Clustering"><a href="#2-Topic-Based-Clustering" class="headerlink" title="2. Topic-Based Clustering"></a>2. Topic-Based Clustering</h3><ul><li><p><code>KeyCluster</code>: clusters semantically similar candidates using Wikipedia and co-occurrence-based statis- tics. <a href="">Clustering to find exemplar terms for keyphrase extraction. Liu et al. (2009b)</a></p><blockquote><p>first grouping candidate words into topics and then, extracting one representative keyphrase from each topic.<br>drawback: by extracting keyphrases from each topic cluster, it essentially gives each topic equal importance. </p></blockquote></li><li><p><code>Topical PageRank</code> <code>(TPR)</code>: <a href="http://www.personal.psu.edu/wzh112/publications/emnlp2010.pdf" target="_blank" rel="noopener">Automatic keyphrase extraction via topic decomposition. Liu 2010</a> overcome drawbacks of KeyCluster.</p><blockquote><p>In particular, they decomposed a document into multiple topics, using topic models, and applied a separate topic-biased PageRank for each topic. The PageRank scores from each topic were then combined into a single score, using as weights the topic proportions returned by topic models for the document.<br>TPR performs significantly better than both <code>tf*idf</code> and <code>TextRank</code> on the DUC-2001 and Inspec datasets.</p></blockquote></li><li><p><code>CommunityCluster</code>: <a href="http://www2009.eprints.org/67/1/p661.pdf" target="_blank" rel="noopener">Extracting Key Terms From Noisy and Multi-theme Documents,Grineva et al. (2009)</a></p><blockquote><p>CommunityCluster gives more weight to more important topics, but unlike TPR, it extracts all candidate keyphrases from an important topic, assuming that a candidate that receives little focus in the text should still be extracted as a keyphrase as long as it is related to an important topic. </p></blockquote></li></ul><h3 id="3-Simultaneous-Learning"><a href="#3-Simultaneous-Learning" class="headerlink" title="3. Simultaneous Learning"></a>3. Simultaneous Learning</h3><h3 id="4-Language-Modeling"><a href="#4-Language-Modeling" class="headerlink" title="4. Language Modeling"></a>4. Language Modeling</h3><p><em>deserves further investigation</em><br><a href="">Tomokiyo and Hurst 2003</a><br>Language Model<br>The foreground corpus is composed of the set of documents from which keyphrases are to be extracted.<br>The background corpus is a large corpus that encodes general knowledge about the world (e.g., the Web).</p><p>LMA uses a language model rather than heuristics to identify phrases, and relies on the language model trained on the background corpus to determine how “unique” a candidate keyphrase is to the domain represented by the foreground corpus. </p><h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset:"></a>Dataset:</h2><ul><li><p>Inspec (Hulth, 2003): This dataset provides 2,000 paper abstracts. We adopt the 500 testing papers and their corresponding uncontrolled keyphrases for evaluation, and the remaining 1,500 papers are used for training the supervised baseline models. </p><blockquote><p>The Hulth 2003 <a href="https://github.com/snkim/ AutomaticKeyphraseExtraction" target="_blank" rel="noopener">Hulth, 2003</a> dataset contains abstracts drawn from the Inspec database of physics and engineering papers. Following our baselines, we used the 500 documents in the validation set and the “uncontrolled” keywords assigned by human annotators. The mean document size is 120 words and on average, 21 keywords (in terms of unigrams) are available for each document.</p></blockquote></li><li><p><a href="https://github.com/snkim/ AutomaticKeyphraseExtraction" target="_blank" rel="noopener">Marujo 2012</a>, containing 450 web news stories of about <code>440 words on average</code>, covering 10 different topics from art and culture to business, sport, and technology (Marujo et al., 2012). </p><blockquote><p>For each story, the keyphrases assigned by at least 9 out of 10 Amazon Mechanical Turkers are provided as gold standard. After splitting the keyphrases into unigrams, this makes for an average of 68 keywords per document, which is much higher than for the two other datasets, even the one comprising long documents (Semeval, see next). </p></blockquote></li></ul><ul><li><p>Krapivin (Krapivin et al., 2008): This dataset provides 2,304 papers with full-text and author-assigned keyphrases. However, the author did not mention how to split testing data, so we selected the first 400 papers in alphabetical order as the testing data, and the remaining papers are used to train the su- pervised baselines.</p></li><li><p>NUS (Nguyen and Kan, 2007): We use the author-assigned keyphrases and treat all 211 papers as the testing data. Since the NUS dataset did not specifically mention the ways of splitting training and testing data, the results of the supervised baseline models are obtained through a five-fold cross-validation. </p></li><li><p>SemEval-2010 (Kim et al., 2010)<a href="https://github.com/boudinfl/centrality_ measures_ijcnlp13/tree/master/data" target="_blank" rel="noopener">Semeval</a>: parsed scientific papers collected from the ACM Digital Library. Each document is approximately 1,860 words in length and is associated with about 24 keywords.</p></li></ul><ul><li>KP20k: We built a new testing dataset that contains the titles, abstracts, and keyphrases of 20,000 scientific articles in computer science. They were randomly selected from our obtained 567,830 articles. Due to the memory limits of implementation, we were not able to train the supervised baselines on the whole training set. Thus we take the 20,000 articles in the validation set to train the supervised baselines. It is worth noting that we also examined their performance by enlarging the training dataset to 50,000 articles, but no significant improvement was observed.</li></ul><h2 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics:"></a>Metrics:</h2><p>Typical approach:<br>(1) to create a mapping between the keyphrases in the gold standard and those in the system output using exact match, and then (2) score the output using evaluation metrics such as <code>precision (P), recall (R), and F-score</code></p><p>Two types of automatic evaluation metrics:  </p><ul><li><p>With <code>exact match</code>. </p><blockquote><p>   These metrics reward a <code>partial match</code> between a predicted keyphrase and a <code>gold</code> keyphrase (i.e., overlapping n-grams) and are commonly used in <code>machine translation (MT)</code> and <code>summarization evaluations</code>. They include <strong>BLEU</strong>, <strong>METEOR</strong>, <strong>NIST</strong>, and <strong>ROUGE</strong>. </p><blockquote><p>   Nevertheless, experiments show that these MT metrics only offer a partial solution to problem with exact match: they can only detect a subset of the near-misses (Kim et al., 2010a).</p></blockquote></blockquote></li><li><p><code>How a system ranks</code> its predictions: </p></li></ul><blockquote><ol><li>Given that two systems A and B have the same number of correct predictions, binary preference measure (Bpref) and mean reciprocal rank (MRR) <a href="">Liu et al., 2010</a> will award more credit to A than to B <strong><em>if the ranks of the correct predictions in A’s output are higher than those in B’s output</em></strong>.</li></ol></blockquote><blockquote><ol><li>R-precision (Rp): IR metric that focuses on ranking: given a document with n gold keyphrases, it computes the precision of a system over its n highest-ranked candidates <a href="">Zesch and Gurevych, 2009</a>. <blockquote><p>The motivation behind the design of Rp is simple: a system will achieve a perfect Rp value if it ranks all the keyphrases above the non-keyphrases.</p></blockquote></li></ol></blockquote><h2 id="The-state-of-Art"><a href="#The-state-of-Art" class="headerlink" title="The state of Art"></a>The state of Art</h2>]]></content>
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keywords Extraction </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux Terminal Notes</title>
      <link href="/2018/03/16/Linux-Terminal-Notes/"/>
      <content type="html"><![CDATA[<h4 id="open-your-operating-system’s-file-explorer-in-this-directory"><a href="#open-your-operating-system’s-file-explorer-in-this-directory" class="headerlink" title="open your operating system’s file explorer in this directory."></a>open your operating system’s file explorer in this directory.</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ open . <span class="comment"># for MAC</span></span><br><span class="line">$ gnome-open . <span class="comment"># for Ubuntu</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Intro to Java</title>
      <link href="/2018/03/16/Intro-to-Java/"/>
      <content type="html"><![CDATA[<p>Intro to Java.<br><a href="https://sp18.datastructur.es/" target="_blank" rel="noopener">CS 16B sp2018</a></p><a id="more"></a><h2 id="Java-program"><a href="#Java-program" class="headerlink" title="Java program"></a>Java program</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloWorld</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Hello world!"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Execute-Java"><a href="#Execute-Java" class="headerlink" title="Execute Java"></a>Execute Java</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ javac HelloWorld.java <span class="comment"># Compiler would generate HelloWorld.class</span></span><br><span class="line">$ java HelloWorld <span class="comment"># Interpreter would run the class file.</span></span><br></pre></td></tr></table></figure><h2 id="Static-Typing"><a href="#Static-Typing" class="headerlink" title="Static Typing"></a>Static Typing</h2><p>Java variables can contain values of that type, and only that type. Furthermore, the type of a variable can never change. The compiler rejects this program out of hand before it even runs.<br>This is in contrast to dynamically typed languages like Python, where users can run into type errors during execution!  </p><h2 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h2><p>Functions that are part of a class are commonly called “methods”.  </p><h2 id="Comments-Javadoc"><a href="#Comments-Javadoc" class="headerlink" title="Comments, Javadoc"></a>Comments, Javadoc</h2><p>Comments where appropriate. Line comments in Java use the // delimiter. Block (a.k.a. multi-line comments) comments use /* and */  </p><h4 id="Javadoc"><a href="#Javadoc" class="headerlink" title="Javadoc"></a>Javadoc</h4><p>The widely used javadoc tool can be used to generate HTML descriptions of your code.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LargerDemo</span> </span>&#123;</span><br><span class="line">    <span class="comment">/** Returns the larger of x and y. */</span>           </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">larger</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (x &gt; y) &#123;</span><br><span class="line">            <span class="keyword">return</span> x;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> y;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(larger(<span class="number">8</span>, <span class="number">10</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span>[] numbers = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">3</span>];</span><br><span class="line">numbers[<span class="number">0</span>] = <span class="number">4</span>;</span><br><span class="line">numbers[<span class="number">1</span>] = <span class="number">7</span>;</span><br><span class="line">numbers[<span class="number">2</span>] = <span class="number">10</span>;</span><br><span class="line">System.out.println(numbers[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span>[] numbers = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">4</span>, <span class="number">7</span>, <span class="number">10</span>&#125;;</span><br><span class="line">System.out.println(numbers[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">String[] a = &#123;<span class="string">"cat"</span>, <span class="string">"dog"</span>, <span class="string">"laser horse"</span>, <span class="string">"ketchup"</span>, <span class="string">"horse"</span>, <span class="string">"horbse"</span>&#125;;</span><br></pre></td></tr></table></figure><h3 id="Command-Line-Arguments"><a href="#Command-Line-Arguments" class="headerlink" title="Command Line Arguments"></a>Command Line Arguments</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ArgsDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(args[<span class="number">0</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ java ArgsDemo these are <span class="built_in">command</span> line arguments</span><br><span class="line">these</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> CS 61B </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Markdown Note</title>
      <link href="/2018/03/16/markdown-note/"/>
      <content type="html"><![CDATA[<p>Basic markdown grammars for a quick reference.</p><a id="more"></a><h3 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h3><blockquote><p>First Level Title<br><code>======</code><br>Second Level Title<br><code>-------</code></p><p><code>#</code> Fisrt Level<br><code>##</code> Second Level<br><code>####</code> forth level<br><code>######</code> sixth level</p></blockquote><h3 id="段落"><a href="#段落" class="headerlink" title="段落"></a>段落</h3><blockquote><p>段落前后有空行就可以。段内强行换行：使用两个空格以上加上回车</p></blockquote><h3 id="区块引用"><a href="#区块引用" class="headerlink" title="区块引用"></a>区块引用</h3><blockquote><p><code>&gt;</code>区块引用</p><blockquote><p><code>&gt;&gt;</code>可以嵌套</p></blockquote></blockquote><h3 id="代码区块"><a href="#代码区块" class="headerlink" title="代码区块"></a>代码区块</h3><blockquote><ol><li>每行或只有第一行加上4个空格或者一个制表符</li><li>or 代码上下两行添加两个反引号</li></ol></blockquote><pre><code>def index():    pass</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public static void main(String[] args)&#123;&#125;</span><br></pre></td></tr></table></figure><h3 id="强调"><a href="#强调" class="headerlink" title="强调"></a>强调</h3><blockquote><p>两侧加上*是斜体<br><em>hi</em><br>两侧加上** 是粗体<br><strong>hi</strong></p></blockquote><h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><blockquote><p>使用+加上一个空格或者制表符</p><ul><li>红豆</li><li>大红豆</li><li>芋头</li></ul></blockquote><blockquote><p>有序列表是</p><ol><li>aa</li><li>bb</li><li>cc</li></ol></blockquote><h3 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h3><blockquote><p>三个或以上*、-、_</p></blockquote><hr><h3 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h3><blockquote><p>行内式: 中括号之间是代替的中文 之后紧跟一个小括号内部写链接<br><a href="https://github.com/younghz/Markdown" target="_blank" rel="noopener">本文的参考来源</a></p></blockquote><h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><blockquote><p>与链接相同 只是在链接前方加个！<br><code>![图片信息](外部链接)</code></p></blockquote><h3 id="反斜杠"><a href="#反斜杠" class="headerlink" title="反斜杠\"></a>反斜杠\</h3><blockquote><p>转义，使符号成为普通符号</p></blockquote><h3 id="bash"><a href="#bash" class="headerlink" title="bash"></a>bash</h3><blockquote><p>``` bash 被围住的内容 ```<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean</span><br><span class="line">$ hexo g</span><br><span class="line">$ hexo d</span><br></pre></td></tr></table></figure></p></blockquote><h3 id="缩进"><a href="#缩进" class="headerlink" title="缩进"></a>缩进</h3><blockquote><p><code>&amp;ensp;</code>输入一个空格<br><code>&amp;emsp;</code>输入两个空格 </p></blockquote><h3 id="标记"><a href="#标记" class="headerlink" title="标记"></a>标记</h3><blockquote><p>`ctrl+a`<br><code>ctrl+a</code></p></blockquote><h3 id="数学公式"><a href="#数学公式" class="headerlink" title="数学公式"></a>数学公式</h3><p>在markdown写作首部添加如下代码：</p><p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>之后写公式:<br>$$公式$$表示行间公式</p>]]></content>
      
      <categories>
          
          <category> Markdown </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hexo Note</title>
      <link href="/2018/03/16/learn-to-write-with-hexo/"/>
      <content type="html"><![CDATA[<ol><li>create new post</li><li>create new page</li></ol><a id="more"></a><h3 id="Write-a-new-post-with-hexo"><a href="#Write-a-new-post-with-hexo" class="headerlink" title="Write a new post with hexo."></a>Write a new post with hexo.</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"new article"</span> <span class="comment">#open source/_posts/new-article.md and edit the post.</span></span><br><span class="line">$ hexo clean <span class="comment">#will clean static-file in public/ and cached-file like db.json</span></span><br><span class="line">$ hexo generate <span class="comment">#generate static files for web pages, in the public/</span></span><br><span class="line">$ hexo server <span class="comment">#start the local server and test the page via localhost:4000</span></span><br><span class="line">$ hexo deploy  <span class="comment">#deploy</span></span><br></pre></td></tr></table></figure><ul><li>Every time after you write a post, input ‘$ hexo s’ to start the server and have a check via localhost:4000</li><li>After start the server, everytime you modify the post, only refreshing the brower will work.</li><li>If you are satisfied with the modification, use ‘$ hexo g’ to generate the static files. (before it, ‘$ hexo clean’ is recommended)</li></ul><hr><h3 id="create-‘ABOUT’-page"><a href="#create-‘ABOUT’-page" class="headerlink" title="create ‘ABOUT’ page"></a>create ‘ABOUT’ page</h3><p>$ hexo new page “about”<br>在主题的_config.yml设置中，写出menu中的about</p><blockquote><p>menu:<br>    home: /<br>    &ensp; archives: /arvhives<br>    &ensp; tags: /tags<br>    &ensp; about: /about</p></blockquote>]]></content>
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/2018/03/15/hello-world/"/>
      <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><a id="more"></a><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
    </entry>
    
  
  
</search>
